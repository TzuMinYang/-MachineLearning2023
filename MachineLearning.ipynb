{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM5DKv/bH6ODtQq3c0+VVAS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"2wkPsSq7worC"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["# 期中報告\n","![](https://i.imgur.com/jKB2Ctt.jpg)\n","\n","### **簡介**\n","因為智慧型手機的無處不在，使人們能夠隨時宣布他們正在觀察的緊急情況。正因如此，很多人想以編程方式監控 Twitter。\n","某位Twitter用戶以隱喻方式使用了“ABLAZE”這個詞。這對人類來說是顯而易見的，尤其是在視覺輔助下，但是機器就不太清楚了。\n","### **參賽原因**\n","作為一位Twitter的資深用戶，在長時間的使用下，我發現Twitter是一個極具影響力和重要性的社交媒體平台，它在全球範圍內有著廣泛的用戶群體，並且在政治、娛樂等各個領域都扮演著重要的角色。Twitter讓我們可以在第一時間了解到最新的新聞和話題，並隨時隨地連接世界各地的人，讓我們分享自己的想法。這也使得Twitter成為了能夠傳播新聞時事與增強社交影響力的重要平台及工具。因為我深刻地了解Twitter對我們有多重要，因此想選擇這個題目。\n","### **資料集與目標介紹**\n","在這個題目中，參賽者需要建立一個機器學習模型來預測哪些推文是關於真實災難的，哪些不是。資料庫包含 10,000 條人工分類的推文數據集，有使用者id、location、text（推文內容）、keyword、target(1代表是，0代表否）。\n","\n","### **程式碼與結果**\n","> #### 載入套件與匯入資料\n","```\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import string\n","from sklearn.feature_extraction.text import CountVectorizer\n","import re\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","train_df = pd.read_csv(\"train.csv\")\n","test_df = pd.read_csv(\"test.csv\")\n","```\n","\n","> #### 查看資料資訊\n","```\n","train_df.head()\n","train_df.info()\n","```\n","\n","> #### 查看有無缺失值並進行資料清理\n","可以看到location有很多缺失值，因此選擇直接用drop將此欄刪除。\n","有嘗試刪除keyword，但沒有太大的效果。\n","```\n","train_df.isnull().sum()\n","test_df.isnull().sum()\n","train = train_df.drop(columns=['location'])\n","test = test_df.drop(columns=['location'])\n","train = train_df.drop(columns=['keyword'])\n","test = test_df.drop(columns=['keyword'])\n","```\n","![](https://i.imgur.com/Iq94Cm3.png)\n","\n","> #### 使用CountVectorizer\n","利用CountVectorizer對text中的字轉為字頻矩陣並存到X，Y則是存train中target的值。\n","將現有資料切分57.15%作為訓練資料集42.85%為測試資料集\n","```\n","vectorizer = CountVectorizer(stop_words='english',ngram_range=(1, 3), max_df=1.0, min_df=1)\n","vectors = vectorizer.fit_transform(train['text'])\n","X = vectors.toarray()\n","Y = train['target'].values\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4285, random_state=67)\n","```\n","\n","> #### 使用Logistic Regression模型\n","```\n","clf = LogisticRegression()\n","clf.fit(X_train,y_train)\n","pred = clf.predict(X_test)\n","clf.score(X_test,y_test)\n","from sklearn.metrics import confusion_matrix,accuracy_score, recall_score, precision_score\n","accuracy_score(y_test,pred)\n","recall_score(y_test,pred)\n","precision_score(y_test,pred)\n","```\n","得到精準率0.7857799570946982、召回率0.6283249460819554、準確率0.8276515151515151\n","![](https://i.imgur.com/Qdt5POH.png)\n","\n","> #### 把得到的結果輸出成.csv檔\n","```\n","forSubmissionDF=pd.DataFrame(columns=['id','target'])\n","forSubmissionDF\n","print(pred.shape)\n","forSubmissionDF['id'] = test.id\n","forSubmissionDF['target'] = pred\n","forSubmissionDF.to_csv('for_submission_20230411.csv', index=False)\n","```\n","### **與上課內容的關聯性**\n","> #### step1:取得資料\n","用上課教的pd.read_csv()取得資料集裡的資料\n","> #### step2:資料清理\n","用上課教的drop()將不需要用到的欄位（keyword與location）刪除\n","> #### step3:資料切割\n","用上課教的train_test_split()將資料切分57.15%作為訓練資料集、42.85%為測試資料集\n","> #### step4:模型選擇與使用\n","使用sklearn中的Logistic Regression模型\n","> #### step5:結果分析與驗證\n","用上課教的accuracy_score, recall_score, precision_score來看預測的精準率、召回率、準確率\n","\n","### **延伸學習**\n","學習如何使用CountVectorizer對text中的字轉為字頻矩陣，並透過這些字頻矩陣來達到預測哪些推文是關於真實災難的目標\n","\n","參考資料：https://blog.csdn.net/weixin_38278334/article/details/82320307\n","\n","### **可能的改善方式**\n","1. 利用train_df.duplicated([\"text\", \"target\"]).sum()檢查text與target是否有相同的資料，有的話可以將其刪除\n","2. 進一步觀察刪除掉的keyword以及location，看有沒有特定的keyword與location，其target較容易為1\n","\n","### **不同的嘗試與結果**\n","1. 改用Random Forest Classifier模型，得到精準率0.7551333129022372、召回率0.501078360891445、準確率0.8690773067331671\n","```\n","from sklearn.ensemble import RandomForestClassifier\n","rf=RandomForestClassifier(n_estimators=150,bootstrap=True)\n","model2=rf.fit(X_train,y_train)\n","model2.score(X_train,y_train)\n","model2.score(X_test,y_test)\n","y_pred=model2.predict(X_test)\n","accuracy_score(y_test,y_pred)\n","recall_score(y_test,y_pred)\n","precision_score(y_test,y_pred)\n","```\n","![](https://i.imgur.com/G0edsmt.png)\n","\n","2. 改用Decision Tree Classifier模型，得到精準率0.8276515151515151、召回率0.7534148094895758、準確率0.9980952380952381，比上課用的Logistic Regression模型表現得更好\n","```\n","from sklearn.tree import DecisionTreeClassifier\n","dt=DecisionTreeClassifier(max_depth=98)\n","model1=dt.fit(X,Y)\n","model1.score(X_train,y_train)\n","model1.score(X_test,y_test)\n","y_pred=model1.predict(X_test)\n","accuracy_score(y_test,y_pred)\n","recall_score(y_test,y_pred)\n","precision_score(y_test,y_pred)\n","```\n","![](https://i.imgur.com/HRrWQhA.png)\n","\n","### **比賽結果說明**\n","1. 使用Logistic Regression模型，結果為0.5311\n","![](https://i.imgur.com/wuvyLCs.png)\n","2. 使用Decision Tree Classifier模型，結果為0.52896\n","![](https://i.imgur.com/EeluvEC.png)\n","雖然Decision Tree Classifier模型精準率較高，但Logistic Regression模型的比賽分數較高\n"],"metadata":{"id":"LcV_jdMCwptl"}},{"cell_type":"markdown","source":[],"metadata":{"id":"aknJOCfMyYBv"}},{"cell_type":"markdown","source":[],"metadata":{"id":"OGJW3H7FyZWx"}},{"cell_type":"code","source":[],"metadata":{"id":"ifJDHDh7yZwK"},"execution_count":null,"outputs":[]}]}